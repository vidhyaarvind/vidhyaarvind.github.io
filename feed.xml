<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-12-22T16:08:43-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Vidhya Arvind</title><author><name>Vidhya Arvind</name><email>vidhya.arvind@gmail.com</email></author><entry><title type="html">How Netflix Delivers Key-Value and Time-Series Storage at Any Scale</title><link href="http://localhost:4000/talks/2023/12/12/cassandra-summit.html" rel="alternate" type="text/html" title="How Netflix Delivers Key-Value and Time-Series Storage at Any Scale" /><published>2023-12-12T00:00:00-08:00</published><updated>2023-12-12T00:00:00-08:00</updated><id>http://localhost:4000/talks/2023/12/12/cassandra-summit</id><content type="html" xml:base="http://localhost:4000/talks/2023/12/12/cassandra-summit.html"><![CDATA[<p>At Netflix, Apache Cassandra’s bread and butter workloads are wide-column storage for Key-Value and Time-Series use cases, but for those that operate at scale they know that if you just structure your tables naively your clusters will become unstable as partitions or columns grow in size. In this talk, we show how to design reliable APIs and lay out Key-Value and Time-Series data in Apache Cassandra for petabyte scale datasets. For example, most Key-Value data is small, but for large partitions we present a novel technique to dynamically bucket data, providing users with fast access for small data and linearly scalable latency for large values. Next, we will show how to lay out Time-Series datasets with table sharding, time and random bucketing so that large partitions are automatically split while maintaining aggressive latency goals. In addition, since we use tables for data expiration rather than compaction, we can get up to 2x more storage out of the same disk space. By combining fully-idempotent APIs, novel table layouts, bucketing algorithms, and compression schemes Netflix has been able to scale Apache Cassandra usage orders of magnitude further than we could before.</p>

<p><a href="/assets/Cassandra Summit_ How Netflix Delivers Key-Value and Time-Series Storage at Any Scale.pdf">Slides</a></p>

<p><a href="https://www.youtube.com/watch?v=sQ-_jFgOBng&amp;t=1s" title="Cassandra Summit 2023"><img src="http://img.youtube.com/vi/sQ-_jFgOBng/0.jpg" alt="Cassandra Summit 2023" /></a></p>]]></content><author><name>Vidhya Arvind</name><email>vidhya.arvind@gmail.com</email></author><category term="talks" /><summary type="html"><![CDATA[At Netflix, Apache Cassandra’s bread and butter workloads are wide-column storage for Key-Value and Time-Series use cases, but for those that operate at scale they know that if you just structure your tables naively your clusters will become unstable as partitions or columns grow in size. In this talk, we show how to design reliable APIs and lay out Key-Value and Time-Series data in Apache Cassandra for petabyte scale datasets. For example, most Key-Value data is small, but for large partitions we present a novel technique to dynamically bucket data, providing users with fast access for small data and linearly scalable latency for large values. Next, we will show how to lay out Time-Series datasets with table sharding, time and random bucketing so that large partitions are automatically split while maintaining aggressive latency goals. In addition, since we use tables for data expiration rather than compaction, we can get up to 2x more storage out of the same disk space. By combining fully-idempotent APIs, novel table layouts, bucketing algorithms, and compression schemes Netflix has been able to scale Apache Cassandra usage orders of magnitude further than we could before.]]></summary></entry></feed>